{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabs the data from ACTT database and exports it to Excel files\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from datetime import datetime\n",
    "\n",
    "DB_HOST = \"aact-db.ctti-clinicaltrials.org\"\n",
    "DB_PORT = 5432\n",
    "DB_NAME = \"aact\"\n",
    "DB_USER = \"USERHERE\"\n",
    "DB_PASS = \"PASSHERE\"\n",
    "\n",
    "# Define the path where you want to save the Excel files\n",
    "OUTPUT_PATH = \"/Users/davidshevchenko/Documents/Github/Clinical-Trials-Dashboard/data\"\n",
    "\n",
    "connection_url = f\"postgresql://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "engine = create_engine(connection_url)\n",
    "\n",
    "def export_filtered_data():\n",
    "    condition_filter = \"\"\"\n",
    "        c.name ILIKE '%breast cancer%'\n",
    "        OR c.name ILIKE '%type 2 diabetes%'\n",
    "        OR c.name ILIKE '%alzheimer%'\n",
    "    \"\"\"\n",
    "    table_queries = {\n",
    "        'studies': text(f\"\"\"\n",
    "            SELECT DISTINCT st.*\n",
    "            FROM studies st\n",
    "            JOIN conditions c ON st.nct_id = c.nct_id\n",
    "            WHERE {condition_filter};\n",
    "        \"\"\"),\n",
    "        'sponsors': text(f\"\"\"\n",
    "            SELECT DISTINCT sp.*\n",
    "            FROM sponsors sp\n",
    "            JOIN studies st ON sp.nct_id = st.nct_id\n",
    "            JOIN conditions c ON st.nct_id = c.nct_id\n",
    "            WHERE {condition_filter};\n",
    "        \"\"\"),\n",
    "        'design_outcomes': text(f\"\"\"\n",
    "            SELECT DISTINCT d_out.*\n",
    "            FROM design_outcomes d_out\n",
    "            JOIN studies st ON d_out.nct_id = st.nct_id\n",
    "            JOIN conditions c ON st.nct_id = c.nct_id\n",
    "            WHERE {condition_filter};\n",
    "        \"\"\"),\n",
    "        'facilities': text(f\"\"\"\n",
    "            SELECT DISTINCT fa.*\n",
    "            FROM facilities fa\n",
    "            JOIN studies st ON fa.nct_id = st.nct_id\n",
    "            JOIN conditions c ON st.nct_id = c.nct_id\n",
    "            WHERE {condition_filter};\n",
    "        \"\"\"),\n",
    "        'eligibilities': text(f\"\"\"\n",
    "            SELECT DISTINCT el.*\n",
    "            FROM eligibilities el\n",
    "            JOIN studies st ON el.nct_id = st.nct_id\n",
    "            JOIN conditions c ON st.nct_id = c.nct_id\n",
    "            WHERE {condition_filter};\n",
    "        \"\"\"),\n",
    "        'interventions': text(f\"\"\"\n",
    "            SELECT DISTINCT i.*\n",
    "            FROM interventions i\n",
    "            JOIN studies st ON i.nct_id = st.nct_id\n",
    "            JOIN conditions c ON st.nct_id = c.nct_id\n",
    "            WHERE {condition_filter};\n",
    "        \"\"\")\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            for table_name, query in table_queries.items():\n",
    "                df = pd.read_sql(query, conn)\n",
    "                output_filename = os.path.join(OUTPUT_PATH, f\"{table_name}.xlsx\")\n",
    "                df.to_excel(output_filename, index=False)\n",
    "                print(f\"Exported {table_name}.xlsx with {len(df)} rows to {OUTPUT_PATH}.\")\n",
    "\n",
    "            columns_for_llm = [\n",
    "                \"nct_id\",\n",
    "                \"parsed_keywords\",\n",
    "                \"category_tags\",\n",
    "                \"summarized_text\",\n",
    "                \"created_at\"\n",
    "            ]\n",
    "            df_llm = pd.DataFrame(columns=columns_for_llm)\n",
    "\n",
    "            llm_filename = os.path.join(OUTPUT_PATH, \"LLM_as_a_parser.xlsx\")\n",
    "            df_llm.to_excel(llm_filename, index=False)\n",
    "            print(f\"Created placeholder LLM data Excel: {llm_filename}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying AACT database or exporting data: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Local DeepSeek LLM Environment\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer\n",
    "\n",
    "model_path = \"deepseek-ai/deepseek-llm-7b-chat\"\n",
    "device = \"mps\"\n",
    "dtype = torch.bfloat16\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=dtype,\n",
    "    device_map=device,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "\n",
    "prompt = \"\"\"\n",
    "<|im_start|>system\n",
    "You are a helpful assistant that answers questions.\n",
    "<|im_end|>\n",
    "<|im_start|>user\n",
    "What is the capital of France?\n",
    "<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model.generate(\n",
    "        **inputs,\n",
    "        streamer=streamer,\n",
    "        max_new_tokens=512,\n",
    "        do_sample=True,\n",
    "        top_p=0.95,\n",
    "        top_k=60,\n",
    "        temperature=0.2,\n",
    "        num_return_sequences=1,\n",
    "    )\n",
    "\n",
    "decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(f\"Model Output:\\n{decoded_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token Cost\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "\n",
    "PRICE_USD_PER_1K_TOKENS_PROMPT = 0.03\n",
    "PRICE_USD_PER_1K_TOKENS_COMPLETION = 0.06\n",
    "\n",
    "ESTIMATED_COMPLETION_TOKENS = 200\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are an advanced AI that parses the clinical trial eligibility criteria text.\n",
    "You will:\n",
    "1) Summarize the major inclusion criteria in bullet points\n",
    "2) Summarize the major exclusion criteria in bullet points\n",
    "3) Identify any special flags or conditions (e.g. 'BRCA mutation', 'HER2', 'Stage IV', 'No prior chemo')\n",
    "\n",
    "Return your output as valid JSON with fields:\n",
    "{\n",
    "  \"inclusion_points\": [...],\n",
    "  \"exclusion_points\": [...],\n",
    "  \"special_flags\": [...]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "USER_PROMPT_TEMPLATE = \"\"\"Please analyze the following 'eligibility criteria' text and generate JSON accordingly:\n",
    "\n",
    "Text to analyze:\n",
    "{TEXT}\"\"\"\n",
    "\n",
    "def build_prompt(text_block):\n",
    "    \"\"\"\n",
    "    Builds a hypothetical ChatCompletion message list\n",
    "    with system + user instructions for GPT-4.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": USER_PROMPT_TEMPLATE.format(TEXT=text_block)}\n",
    "    ]\n",
    "    return messages\n",
    "\n",
    "def num_tokens_from_messages(messages, model=\"gpt-4\"):\n",
    "    \"\"\"\n",
    "    Approximate token usage for GPT-4 by using 'gpt-3.5-turbo' encoding\n",
    "    (closest known approach).\n",
    "    \"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "    num_tokens = 0\n",
    "    for msg in messages:\n",
    "        num_tokens += 4\n",
    "        for key, value in msg.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "    num_tokens += 2\n",
    "    return num_tokens\n",
    "\n",
    "def main():\n",
    "    DATA_FOLDER = \"/Users/davidshevchenko/Documents/Github/Clinical-Trials-Dashboard/data\"\n",
    "    excel_file = os.path.join(DATA_FOLDER, \"eligibilities.xlsx\")\n",
    "    column_with_text = \"criteria\"\n",
    "\n",
    "    df = pd.read_excel(excel_file)\n",
    "    print(f\"Loaded {len(df)} rows from {excel_file}.\")\n",
    "\n",
    "    total_prompt_tokens = 0\n",
    "    total_calls = 0\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        text_col = row.get(column_with_text, \"\")\n",
    "        if not isinstance(text_col, str) or not text_col.strip():\n",
    "            continue\n",
    "\n",
    "        messages = build_prompt(text_col)\n",
    "        prompt_tokens = num_tokens_from_messages(messages, model=\"gpt-4\")\n",
    "\n",
    "        total_prompt_tokens += prompt_tokens\n",
    "        total_calls += 1\n",
    "\n",
    "    print(f\"Number of rows with non-empty '{column_with_text}': {total_calls}\")\n",
    "    print(f\"Total prompt tokens (input): {total_prompt_tokens}\")\n",
    "\n",
    "    total_completion_tokens = total_calls * ESTIMATED_COMPLETION_TOKENS\n",
    "    print(f\"Estimated total completion tokens (output): {total_completion_tokens}\")\n",
    "\n",
    "    prompt_tokens_k = total_prompt_tokens / 1000\n",
    "    completion_tokens_k = total_completion_tokens / 1000\n",
    "\n",
    "    cost_prompt = prompt_tokens_k * PRICE_USD_PER_1K_TOKENS_PROMPT\n",
    "    cost_completion = completion_tokens_k * PRICE_USD_PER_1K_TOKENS_COMPLETION\n",
    "    total_cost = cost_prompt + cost_completion\n",
    "\n",
    "    print(\"----- COST ESTIMATE -----\")\n",
    "    print(f\"Prompt tokens cost:     ${cost_prompt:.2f} (for ~{prompt_tokens_k:.2f}k tokens)\")\n",
    "    print(f\"Completion tokens cost: ${cost_completion:.2f} (for ~{completion_tokens_k:.2f}k tokens)\")\n",
    "    print(f\"Total estimated cost:   ${total_cost:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepSeek LM Locally Run\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 1) Configuration\n",
    "# ------------------------------------------------\n",
    "MODEL_PATH = \"deepseek-ai/deepseek-llm-7b-chat\"\n",
    "DEVICE = \"mps\"\n",
    "DTYPE = torch.bfloat16\n",
    "NUM_ROWS = 10\n",
    "\n",
    "DATA_FOLDER = \"/Users/davidshevchenko/Documents/Github/Clinical-Trials-Dashboard/data\"\n",
    "EXCEL_INPUT = os.path.join(DATA_FOLDER, \"eligibilities.xlsx\")\n",
    "EXCEL_OUTPUT = os.path.join(DATA_FOLDER, \"LLM_as_a_parser.xlsx\")\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 2) System & User Prompts\n",
    "# ------------------------------------------------\n",
    "SYSTEM_PROMPT = \"\"\"You are an AI that parses clinical trial eligibility criteria into specific fields.\n",
    "For each criteria text, identify and extract the following in valid JSON only:\n",
    "\n",
    "1) performance_status: e.g. \"ECOG 0-1\" or \"KPS ≥70\" if mentioned, or \"N/A\" if absent\n",
    "2) biomarkers: a list of relevant markers (e.g. \"BRCA\", \"HER2_neg\", \"EGFR\", \"ER_neg\")\n",
    "3) no_prior_chemo: boolean, true if text excludes participants with prior chemo, otherwise false\n",
    "4) pregnancy_excluded: boolean, true if pregnant/breastfeeding women are excluded, otherwise false\n",
    "5) excluded_comorbidities: array of major excluded diseases/conditions (e.g. \"uncontrolled seizures\", \"HIV infection\")\n",
    "6) other_special_requirements: array for any additional must-have or must-not-have conditions (e.g., \"must have tissue blocks\", \"no major surgery within 14 days\")\n",
    "\n",
    "Return valid JSON only, with no extra text or special characters (like code fences). For example:\n",
    "{\n",
    "  \"performance_status\": \"ECOG 0-1\",\n",
    "  \"biomarkers\": [\"BRCA\", \"HER2_neg\"],\n",
    "  \"no_prior_chemo\": false,\n",
    "  \"pregnancy_excluded\": true,\n",
    "  \"excluded_comorbidities\": [\"uncontrolled seizures\", \"heart failure\"],\n",
    "  \"other_special_requirements\": [\"tumor blocks\", \"no major surgery within 14 days\"]\n",
    "}\"\"\"\n",
    "\n",
    "USER_PROMPT_TEMPLATE = \"\"\"Below is the full eligibility criteria for a clinical trial:\n",
    "\n",
    "{CRITERIA}\n",
    "\n",
    "Please parse it into the requested fields (performance_status, biomarkers, etc.).\"\"\"\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 3) Load Model\n",
    "# ------------------------------------------------\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    torch_dtype=DTYPE,\n",
    "    device_map=DEVICE,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "def generate_response(system_prompt, user_prompt, max_new_tokens=768):\n",
    "    combined_prompt = f\"\"\"\n",
    "<|im_start|>system\n",
    "{system_prompt}\n",
    "<|im_end|>\n",
    "\n",
    "<|im_start|>user\n",
    "{user_prompt}\n",
    "<|im_end|>\n",
    "\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "    inputs = tokenizer(combined_prompt, return_tensors=\"pt\").to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_tokens = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            temperature=0.3,\n",
    "        )\n",
    "    return tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n",
    "\n",
    "def main():\n",
    "    # ------------------------------------------------\n",
    "    # 4) Load data and limit to first 10 rows\n",
    "    # ------------------------------------------------\n",
    "    df = pd.read_excel(EXCEL_INPUT)\n",
    "    print(f\"Loaded {len(df)} rows from {EXCEL_INPUT}. Only processing first {NUM_ROWS} rows.\")\n",
    "    df = df.head(NUM_ROWS)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        nct_id = row.get(\"nct_id\", \"\")\n",
    "        criteria_text = row.get(\"criteria\", \"\")\n",
    "\n",
    "        if not isinstance(criteria_text, str) or not criteria_text.strip():\n",
    "            continue\n",
    "\n",
    "        user_prompt = USER_PROMPT_TEMPLATE.format(CRITERIA=criteria_text)\n",
    "        raw_output = generate_response(SYSTEM_PROMPT, user_prompt)\n",
    "\n",
    "        start = raw_output.find(\"{\")\n",
    "        end = raw_output.rfind(\"}\")\n",
    "        if start != -1 and end != -1 and end > start:\n",
    "            json_substring = raw_output[start:end+1]\n",
    "        else:\n",
    "            json_substring = raw_output\n",
    "\n",
    "        results.append({\n",
    "            \"nct_id\": nct_id,\n",
    "            \"criteria_json_substring\": json_substring,\n",
    "            \"full_raw_response\": raw_output\n",
    "        })\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # 5) Save to Excel\n",
    "    # ------------------------------------------------\n",
    "    out_df = pd.DataFrame(results)\n",
    "    out_df.to_excel(EXCEL_OUTPUT, index=False)\n",
    "    print(f\"Done. Saved results to {EXCEL_OUTPUT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT 4 API\n",
    "\n",
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "# ------------------------------\n",
    "# 1) Configuration\n",
    "# ------------------------------\n",
    "openai.api_key = \"Key Here\"\n",
    "\n",
    "\n",
    "MODEL_NAME = \"gpt-4\"\n",
    "NUM_ROWS = 750\n",
    "\n",
    "DATA_FOLDER = \"/Users/davidshevchenko/Documents/Github/Clinical-Trials-Dashboard/data\"\n",
    "EXCEL_INPUT = os.path.join(DATA_FOLDER, \"eligibilities.xlsx\")\n",
    "EXCEL_OUTPUT = os.path.join(DATA_FOLDER, \"LLM_as_a_parser.xlsx\")\n",
    "\n",
    "# ------------------------------\n",
    "# 2) Prompts\n",
    "# ------------------------------\n",
    "SYSTEM_PROMPT = \"\"\"You are an advanced AI that extracts key fields from unstructured clinical trial eligibility criteria\n",
    "and returns them in valid JSON. If a field is not found, set it to 'N/A', false, or [].\n",
    "\n",
    "We want these fields in the JSON:\n",
    "1) performance_status (e.g., \"ECOG 0-1\" or \"KPS >=70\" or \"N/A\")\n",
    "2) biomarkers (array, e.g., [\"BRCA\"], or [])\n",
    "3) no_prior_chemo (boolean)\n",
    "4) pregnancy_excluded (boolean)\n",
    "5) excluded_comorbidities (array of conditions)\n",
    "6) other_special_requirements (array)\n",
    "\n",
    "Return **only** valid JSON from the first '{' to the last '}', with no extra text.\n",
    "If you see disclaimers or code fences, remove them.\n",
    "\n",
    "### One-Shot Example\n",
    "\n",
    "Example Criteria:\n",
    "\"Inclusion:\n",
    "- ECOG 0-1\n",
    "Exclusion:\n",
    "- No prior chemo, uncontrolled seizures\n",
    "\"\n",
    "\n",
    "Example JSON:\n",
    "{\n",
    "  \"performance_status\": \"ECOG 0-1\",\n",
    "  \"biomarkers\": [],\n",
    "  \"no_prior_chemo\": true,\n",
    "  \"pregnancy_excluded\": false,\n",
    "  \"excluded_comorbidities\": [\"uncontrolled seizures\"],\n",
    "  \"other_special_requirements\": []\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "USER_PROMPT_TEMPLATE = \"\"\"Below is the full eligibility criteria for a clinical trial:\n",
    "\n",
    "{CRITERIA}\n",
    "\n",
    "Return these 6 fields in valid JSON, from the first '{{' to the last '}}' only.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 3) GPT-4 API Call\n",
    "# ------------------------------\n",
    "def call_gpt4_api(system_prompt, user_prompt):\n",
    "    \"\"\"\n",
    "    Uses openai>=1.0.0 style chat.completions.create for GPT-4.\n",
    "    \"\"\"\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        max_tokens=800,\n",
    "        top_p=0.9,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def extract_json_substring(full_text):\n",
    "    \"\"\"\n",
    "    Extract the substring from the first '{' to the last '}'.\n",
    "    If no braces found, return the entire text for fallback.\n",
    "    \"\"\"\n",
    "    start = full_text.find(\"{\")\n",
    "    end = full_text.rfind(\"}\")\n",
    "    if start != -1 and end != -1 and end > start:\n",
    "        return full_text[start:end+1]\n",
    "    else:\n",
    "        return full_text\n",
    "\n",
    "# ------------------------------\n",
    "# 4) Main Script\n",
    "# ------------------------------\n",
    "def main():\n",
    "    df = pd.read_excel(EXCEL_INPUT)\n",
    "    print(f\"Loaded {len(df)} rows from {EXCEL_INPUT}. Only processing first {NUM_ROWS} rows.\")\n",
    "    df = df.head(NUM_ROWS)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        nct_id = row.get(\"nct_id\", \"\")\n",
    "        criteria_text = row.get(\"criteria\", \"\")\n",
    "\n",
    "        if not isinstance(criteria_text, str) or not criteria_text.strip():\n",
    "            continue\n",
    "\n",
    "        user_prompt = USER_PROMPT_TEMPLATE.format(CRITERIA=criteria_text)\n",
    "\n",
    "        raw_output = call_gpt4_api(SYSTEM_PROMPT, user_prompt)\n",
    "\n",
    "        json_substring = extract_json_substring(raw_output)\n",
    "\n",
    "        results.append({\n",
    "            \"nct_id\": nct_id,\n",
    "            \"full_raw_response\": raw_output,\n",
    "            \"criteria_json_substring\": json_substring\n",
    "        })\n",
    "\n",
    "    out_df = pd.DataFrame(results)\n",
    "    out_df.to_excel(EXCEL_OUTPUT, index=False)\n",
    "    print(f\"Done. Saved results to {EXCEL_OUTPUT}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepSeek Distill R1\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "# ------------------------------\n",
    "# 1) Configuration\n",
    "# ------------------------------\n",
    "MODEL_NAME = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "DATA_FOLDER = \"/Users/davidshevchenko/Documents/Github/Clinical-Trials-Dashboard/data\"\n",
    "EXCEL_INPUT = os.path.join(DATA_FOLDER, \"eligibilities.xlsx\")\n",
    "EXCEL_OUTPUT = os.path.join(DATA_FOLDER, \"LLM_as_a_parser_DeepSeek_Distill_Qwen.xlsx\")\n",
    "\n",
    "NUM_ROWS = 10\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "SYSTEM_INSTRUCTIONS = \"\"\"You are an AI that extracts key fields from unstructured clinical trial eligibility text\n",
    "and returns them in valid JSON only. If not mentioned, set \"N/A\", false, or [].\n",
    "\n",
    "We want the following fields:\n",
    "1) performance_status (e.g., \"ECOG 0-1\" or \"N/A\")\n",
    "2) biomarkers (array, e.g. [\"BRCA\"], or [])\n",
    "3) no_prior_chemo (boolean)\n",
    "4) pregnancy_excluded (boolean)\n",
    "5) excluded_comorbidities (array)\n",
    "6) other_special_requirements (array)\n",
    "\n",
    "Return only valid JSON from the first '{' to the last '}'—no disclaimers, code fences, or additional text.\n",
    "\"\"\"\n",
    "\n",
    "USER_PROMPT_TEMPLATE = \"\"\"Below is the full eligibility criteria for a clinical trial:\n",
    "\n",
    "{CRITERIA}\n",
    "\n",
    "Return the 6 fields in valid JSON, from the first '{{' to the last '}}' only.\n",
    "\"\"\"\n",
    "\n",
    "def build_prompt(system_instructions, user_text):\n",
    "    \"\"\"\n",
    "    Many Hugging Face LLMs expect a single text prompt\n",
    "    (unless they are specifically chat-based).\n",
    "    We'll just concatenate: system instructions + user text.\n",
    "    \"\"\"\n",
    "    final_prompt = f\"[SYSTEM]\\n{system_instructions}\\n\\n[USER]\\n{user_text}\\n\\n[ASSISTANT]\"\n",
    "    return final_prompt\n",
    "\n",
    "def extract_json_substring(full_text):\n",
    "    start = full_text.find(\"{\")\n",
    "    end = full_text.rfind(\"}\")\n",
    "    if start != -1 and end != -1 and end > start:\n",
    "        return full_text[start:end+1]\n",
    "    else:\n",
    "        return full_text\n",
    "\n",
    "def main():\n",
    "    # ------------------------------\n",
    "    # 2) Load the Distilled Qwen 1.5B Model\n",
    "    # ------------------------------\n",
    "    print(f\"Loading model from Hugging Face: {MODEL_NAME}\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.float16\n",
    "    )\n",
    "\n",
    "    generate_text = pipeline(\n",
    "        task=\"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=2048,\n",
    "        temperature=0.2,\n",
    "        do_sample=False\n",
    "    )\n",
    "\n",
    "    # ------------------------------\n",
    "    # 3) Read Input Data\n",
    "    # ------------------------------\n",
    "    df = pd.read_excel(EXCEL_INPUT)\n",
    "    df = df.head(NUM_ROWS)\n",
    "    results = []\n",
    "\n",
    "    batch_start = 0\n",
    "    total = len(df)\n",
    "\n",
    "    while batch_start < total:\n",
    "        batch_end = min(batch_start + BATCH_SIZE, total)\n",
    "        batch_df = df.iloc[batch_start:batch_end]\n",
    "\n",
    "        for idx, row in batch_df.iterrows():\n",
    "            nct_id = row.get(\"nct_id\", \"\")\n",
    "            criteria_text = row.get(\"criteria\", \"\")\n",
    "            if not isinstance(criteria_text, str) or not criteria_text.strip():\n",
    "                continue\n",
    "\n",
    "            user_prompt = USER_PROMPT_TEMPLATE.format(CRITERIA=criteria_text)\n",
    "            final_prompt = build_prompt(SYSTEM_INSTRUCTIONS, user_prompt)\n",
    "\n",
    "            outputs = generate_text(\n",
    "                final_prompt,\n",
    "                max_new_tokens=512,\n",
    "                num_return_sequences=1\n",
    "            )\n",
    "            raw_output = outputs[0][\"generated_text\"]\n",
    "\n",
    "            json_substring = extract_json_substring(raw_output)\n",
    "\n",
    "            results.append({\n",
    "                \"nct_id\": nct_id,\n",
    "                \"full_raw_response\": raw_output,\n",
    "                \"criteria_json_substring\": json_substring\n",
    "            })\n",
    "\n",
    "        out_df = pd.DataFrame(results)\n",
    "        out_df.to_excel(EXCEL_OUTPUT, index=False)\n",
    "        print(f\"Processed rows {batch_start} to {batch_end-1}, partial results in {EXCEL_OUTPUT}\")\n",
    "\n",
    "        batch_start = batch_end\n",
    "\n",
    "    print(\"All done, final saved.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT 4 Through Azure\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# Environment/config variables\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "\n",
    "# Instantiate the AzureOpenAI client\n",
    "client = AzureOpenAI(\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT\n",
    ")\n",
    "\n",
    "NUM_ROWS = 500\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "DATA_FOLDER = \"/Users/davidshevchenko/Documents/Github/Clinical-Trials-Dashboard/data\"\n",
    "EXCEL_INPUT = os.path.join(DATA_FOLDER, \"eligibilities.xlsx\")\n",
    "EXCEL_OUTPUT = os.path.join(DATA_FOLDER, \"LLM_as_a_parser.xlsx\")\n",
    "\n",
    "# Prompt instructions\n",
    "SYSTEM_PROMPT = \"\"\"You are an advanced AI that extracts key fields from unstructured clinical trial eligibility text\n",
    "and returns them in valid JSON only. If not mentioned, set 'N/A', false, or [].\n",
    "\n",
    "We want these fields:\n",
    "1) performance_status (e.g. \"ECOG 0-1\" or \"N/A\")\n",
    "2) biomarkers (array, e.g. [\"BRCA\"], or [])\n",
    "3) no_prior_chemo (boolean)\n",
    "4) pregnancy_excluded (boolean)\n",
    "5) excluded_comorbidities (array)\n",
    "6) other_special_requirements (array)\n",
    "\n",
    "Return only valid JSON from the first '{' to the last '}' with no disclaimers.\n",
    "\"\"\"\n",
    "\n",
    "USER_PROMPT_TEMPLATE = \"\"\"Below is the full eligibility criteria for a clinical trial:\n",
    "\n",
    "{CRITERIA}\n",
    "\n",
    "Return the 6 fields in valid JSON, from the first '{{' to the last '}}' only.\n",
    "\"\"\"\n",
    "\n",
    "def call_azure_openai_api(system_prompt, user_prompt):\n",
    "    \"\"\"\n",
    "    Calls the AzureOpenAI client for a chat completion using your GPT-4 deployment.\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=AZURE_OPENAI_DEPLOYMENT_NAME,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        max_tokens=800,\n",
    "        top_p=0.9\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def main():\n",
    "    df = pd.read_excel(EXCEL_INPUT)\n",
    "    df = df.head(NUM_ROWS)\n",
    "    results = []\n",
    "\n",
    "    total_rows = len(df)\n",
    "    batch_start = 0\n",
    "\n",
    "    while batch_start < total_rows:\n",
    "        batch_end = min(batch_start + BATCH_SIZE, total_rows)\n",
    "        batch_df = df.iloc[batch_start:batch_end]\n",
    "\n",
    "        for idx, row in batch_df.iterrows():\n",
    "            nct_id = row.get(\"nct_id\", \"\")\n",
    "            criteria_text = row.get(\"criteria\", \"\")\n",
    "\n",
    "            if not isinstance(criteria_text, str) or not criteria_text.strip():\n",
    "                continue\n",
    "\n",
    "            user_prompt = USER_PROMPT_TEMPLATE.format(CRITERIA=criteria_text)\n",
    "            raw_output = call_azure_openai_api(SYSTEM_PROMPT, user_prompt)\n",
    "\n",
    "            results.append({\n",
    "                \"nct_id\": nct_id,\n",
    "                \"full_raw_response\": raw_output\n",
    "            })\n",
    "\n",
    "        out_df = pd.DataFrame(results)\n",
    "        out_df.to_excel(EXCEL_OUTPUT, index=False)\n",
    "        print(f\"Processed rows {batch_start} to {batch_end-1}, partial results -> {EXCEL_OUTPUT}\")\n",
    "\n",
    "        batch_start = batch_end\n",
    "\n",
    "    print(\"All done, final results saved.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing JSON Output\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "DATA_FOLDER = \"/Users/davidshevchenko/Documents/Github/Clinical-Trials-Dashboard/data\"\n",
    "INPUT_FILE = os.path.join(DATA_FOLDER, \"LLM_as_a_parser.xlsx\")\n",
    "OUTPUT_FILE = os.path.join(DATA_FOLDER, \"LLM_as_a_parser_parsed_values.xlsx\")\n",
    "\n",
    "def parse_json_fields():\n",
    "    df = pd.read_excel(INPUT_FILE)\n",
    "\n",
    "    extracted_rows = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        nct_id = row[\"nct_id\"]\n",
    "        raw_response = str(row[\"full_raw_response\"])\n",
    "\n",
    "        cleaned_response = re.sub(r\"^```(?:json)?\", \"\", raw_response.strip(), flags=re.IGNORECASE).strip()\n",
    "        cleaned_response = re.sub(r\"```$\", \"\", cleaned_response, flags=re.IGNORECASE).strip()\n",
    "\n",
    "        try:\n",
    "            data = json.loads(cleaned_response)\n",
    "\n",
    "            fields = [\n",
    "                \"performance_status\",\n",
    "                \"biomarkers\",\n",
    "                \"no_prior_chemo\",\n",
    "                \"pregnancy_excluded\",\n",
    "                \"excluded_comorbidities\",\n",
    "                \"other_special_requirements\"\n",
    "            ]\n",
    "\n",
    "            for field_name in fields:\n",
    "                field_value = data.get(field_name, None)\n",
    "                extracted_rows.append({\n",
    "                    \"nct_id\": nct_id,\n",
    "                    \"raw_response\": raw_response,\n",
    "                    \"field_name\": field_name,\n",
    "                    \"field_value\": field_value\n",
    "                })\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            extracted_rows.append({\n",
    "                \"nct_id\": nct_id,\n",
    "                \"raw_response\": raw_response,\n",
    "                \"field_name\": \"error\",\n",
    "                \"field_value\": \"JSON parse error\"\n",
    "            })\n",
    "\n",
    "    parsed_df = pd.DataFrame(extracted_rows)\n",
    "\n",
    "    parsed_df.to_excel(OUTPUT_FILE, index=False)\n",
    "    print(f\"Parsed results saved to {OUTPUT_FILE}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab Conditions Table\n",
    "\n",
    "DB_HOST = \"aact-db.ctti-clinicaltrials.org\"\n",
    "DB_PORT = 5432\n",
    "DB_NAME = \"aact\"\n",
    "DB_USER = \"USERHERE\"\n",
    "DB_PASS = \"PASSHERE\"\n",
    "\n",
    "OUTPUT_PATH = \"/Users/davidshevchenko/Documents/Github/Clinical-Trials-Dashboard/data\"\n",
    "\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "connection_url = f\"postgresql://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "engine = create_engine(connection_url)\n",
    "\n",
    "def export_conditions_data():\n",
    "    \"\"\"\n",
    "    Connects to the AACT database, filters for trials mentioning\n",
    "    'Breast Cancer', 'Type 2 Diabetes', or 'Alzheimer'\n",
    "    in the conditions.name field, and exports all columns (*) from\n",
    "    the 'conditions' table to a single Excel file in OUTPUT_PATH.\n",
    "    \"\"\"\n",
    "\n",
    "    condition_filter = \"\"\"\n",
    "        c.name ILIKE '%breast cancer%'\n",
    "        OR c.name ILIKE '%type 2 diabetes%'\n",
    "        OR c.name ILIKE '%alzheimer%'\n",
    "    \"\"\"\n",
    "\n",
    "    conditions_query = text(f\"\"\"\n",
    "        SELECT DISTINCT c.*\n",
    "        FROM conditions c\n",
    "        JOIN studies st ON c.nct_id = st.nct_id\n",
    "        WHERE {condition_filter};\n",
    "    \"\"\")\n",
    "\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            df_conditions = pd.read_sql(conditions_query, conn)\n",
    "            output_file = os.path.join(OUTPUT_PATH, \"conditions.xlsx\")\n",
    "            df_conditions.to_excel(output_file, index=False)\n",
    "            print(f\"Exported conditions.xlsx with {len(df_conditions)} rows to {OUTPUT_PATH}.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error exporting conditions table: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot Table\n",
    "\n",
    "DATA_FOLDER = \"/Users/davidshevchenko/Documents/Github/Clinical-Trials-Dashboard/data\"\n",
    "INPUT_FILE = os.path.join(DATA_FOLDER, \"LLM_as_a_parser.xlsx\")\n",
    "OUTPUT_FILE = os.path.join(DATA_FOLDER, \"LLM_as_a_parser_parsed_values_pivoted.xlsx\")\n",
    "\n",
    "def parse_json_fields_and_pivot():\n",
    "    df = pd.read_excel(INPUT_FILE)\n",
    "\n",
    "    extracted_rows = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        nct_id = row[\"nct_id\"]\n",
    "        raw_response = str(row[\"full_raw_response\"])\n",
    "\n",
    "        cleaned_response = re.sub(r\"^```(?:json)?\", \"\", raw_response.strip(), flags=re.IGNORECASE).strip()\n",
    "        cleaned_response = re.sub(r\"```$\", \"\", cleaned_response, flags=re.IGNORECASE).strip()\n",
    "\n",
    "        try:\n",
    "            data = json.loads(cleaned_response)\n",
    "\n",
    "            fields = [\n",
    "                \"performance_status\",\n",
    "                \"biomarkers\",\n",
    "                \"no_prior_chemo\",\n",
    "                \"pregnancy_excluded\",\n",
    "                \"excluded_comorbidities\",\n",
    "                \"other_special_requirements\"\n",
    "            ]\n",
    "\n",
    "            for field_name in fields:\n",
    "                field_value = data.get(field_name, None)\n",
    "                extracted_rows.append({\n",
    "                    \"nct_id\": nct_id,\n",
    "                    \"raw_response\": raw_response,\n",
    "                    \"field_name\": field_name,\n",
    "                    \"field_value\": field_value\n",
    "                })\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            extracted_rows.append({\n",
    "                \"nct_id\": nct_id,\n",
    "                \"raw_response\": raw_response,\n",
    "                \"field_name\": \"error\",\n",
    "                \"field_value\": \"JSON parse error\"\n",
    "            })\n",
    "\n",
    "    tall_df = pd.DataFrame(extracted_rows)\n",
    "\n",
    "    latest_raw = (\n",
    "        tall_df.groupby(\"nct_id\")[\"raw_response\"]\n",
    "        .last()  # or .first()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    pivoted = tall_df.pivot(index=\"nct_id\", columns=\"field_name\", values=\"field_value\")\n",
    "\n",
    "    pivoted = pivoted.reset_index().merge(latest_raw, on=\"nct_id\", how=\"left\")\n",
    "\n",
    "    pivoted.to_excel(OUTPUT_FILE, index=False)\n",
    "    print(f\"Pivoted results saved to {OUTPUT_FILE}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Outcomes Extraction\n",
    "\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "\n",
    "# Instantiate the AzureOpenAI client\n",
    "client = AzureOpenAI(\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT\n",
    ")\n",
    "\n",
    "# Adjust as needed\n",
    "NUM_ROWS = 500\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "DATA_FOLDER = \"/Users/davidshevchenko/Documents/Github/Clinical-Trials-Dashboard/data\"\n",
    "EXCEL_INPUT = os.path.join(DATA_FOLDER, \"design_outcomes.xlsx\")\n",
    "EXCEL_OUTPUT = os.path.join(DATA_FOLDER, \"ai_outcomes.xlsx\")\n",
    "\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are an advanced AI that extracts key fields from unstructured clinical trial outcome text\n",
    "and returns them in valid JSON only. If not mentioned, set 'N/A' or [].\n",
    "\n",
    "We want these fields:\n",
    "1) key_variables (array/list of strings) - e.g. [\"HbA1c\",\"Blood Pressure\"]\n",
    "2) time_frame (string) - e.g. \"12 weeks\",\"Up to 5 years\", or \"N/A\"\n",
    "3) outcome_category (string) - e.g. \"Survival\",\"Quality of Life\",\"Biomarker\",\"Safety\",\"Other\"\n",
    "\n",
    "Return only valid JSON from the first '{' to the last '}' with no disclaimers.\n",
    "\"\"\"\n",
    "\n",
    "USER_PROMPT_TEMPLATE = \"\"\"Below is an outcome measure text for a clinical trial:\n",
    "\n",
    "{OUTCOME_TEXT}\n",
    "\n",
    "Return 3 fields in valid JSON, from the first '{{' to the last '}}' only:\n",
    "- key_variables (array)\n",
    "- time_frame (string)\n",
    "- outcome_category (string)\n",
    "\"\"\"\n",
    "\n",
    "def call_azure_openai_api(system_prompt, user_prompt):\n",
    "    \"\"\"\n",
    "    Calls the AzureOpenAI client for a chat completion using your GPT-4 deployment.\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=AZURE_OPENAI_DEPLOYMENT_NAME,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        max_tokens=800,\n",
    "        top_p=0.9\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def main():\n",
    "    df = pd.read_excel(EXCEL_INPUT)\n",
    "    df = df.head(NUM_ROWS)\n",
    "    results = []\n",
    "\n",
    "    total_rows = len(df)\n",
    "    batch_start = 0\n",
    "\n",
    "    while batch_start < total_rows:\n",
    "        batch_end = min(batch_start + BATCH_SIZE, total_rows)\n",
    "        batch_df = df.iloc[batch_start:batch_end]\n",
    "\n",
    "        for idx, row in batch_df.iterrows():\n",
    "            nct_id = row.get(\"nct_id\", \"\")\n",
    "            text_for_llm = row.get(\"measure\", \"\")\n",
    "\n",
    "            if not isinstance(text_for_llm, str) or not text_for_llm.strip():\n",
    "                continue\n",
    "\n",
    "            user_prompt = USER_PROMPT_TEMPLATE.format(OUTCOME_TEXT=text_for_llm)\n",
    "            raw_output = call_azure_openai_api(SYSTEM_PROMPT, user_prompt)\n",
    "\n",
    "            results.append({\n",
    "                \"nct_id\": nct_id,\n",
    "                \"full_raw_response\": raw_output\n",
    "            })\n",
    "\n",
    "        out_df = pd.DataFrame(results)\n",
    "        out_df.to_excel(EXCEL_OUTPUT, index=False)\n",
    "        print(f\"Processed rows {batch_start} to {batch_end - 1}, partial results -> {EXCEL_OUTPUT}\")\n",
    "\n",
    "        batch_start = batch_end\n",
    "\n",
    "    print(\"All done, final results saved to:\", EXCEL_OUTPUT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Intervention Extraction\n",
    "\n",
    "# Azure OpenAI environment/config variables\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "\n",
    "# Instantiate the AzureOpenAI client\n",
    "client = AzureOpenAI(\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT\n",
    ")\n",
    "\n",
    "# Adjust these as needed\n",
    "NUM_ROWS = 500\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "DATA_FOLDER = \"/Users/davidshevchenko/Documents/Github/Clinical-Trials-Dashboard/data\"\n",
    "EXCEL_INPUT = os.path.join(DATA_FOLDER, \"interventions.xlsx\")\n",
    "EXCEL_OUTPUT = os.path.join(DATA_FOLDER, \"ai_interventions.xlsx\")\n",
    "\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are an advanced AI that extracts structured info from unstructured clinical trial interventions.\n",
    "Return only valid JSON. If data is not mentioned, use 'N/A' or an empty array/list.\n",
    "\n",
    "We want these 5 fields:\n",
    "1) drug_names (array of strings) - e.g. [\"Carboplatin\",\"Paclitaxel\"]\n",
    "2) dosages (array of strings) - e.g. [\"80 mg/m2 weekly\",\"AUC=5\",\"200 mg once daily\"]\n",
    "3) administration_route (string) - e.g. \"Intravenous\",\"Oral\",\"N/A\"\n",
    "4) frequency (string) - e.g. \"Every 3 weeks for 4 cycles\",\"Once daily\",\"N/A\"\n",
    "5) therapy_class (string) - e.g. \"Chemotherapy\",\"Immunotherapy\",\"Hormonal\",\"Targeted Therapy\",\"Supportive Care\",\"Other\"\n",
    "\n",
    "Return only valid JSON from the first '{' to the last '}' with no disclaimers.\n",
    "\"\"\"\n",
    "\n",
    "USER_PROMPT_TEMPLATE = \"\"\"Below is the intervention description for a clinical trial:\n",
    "\n",
    "{INTERVENTION_TEXT}\n",
    "\n",
    "Please return the 5 fields in valid JSON, from the first '{{' to the last '}}'.\n",
    "\"\"\"\n",
    "\n",
    "def call_azure_openai_api(system_prompt, user_prompt):\n",
    "    \"\"\"\n",
    "    Calls the AzureOpenAI client for a chat completion using your GPT-4 deployment.\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=AZURE_OPENAI_DEPLOYMENT_NAME,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        max_tokens=800,\n",
    "        top_p=0.9\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def main():\n",
    "    df = pd.read_excel(EXCEL_INPUT)\n",
    "    df = df.head(NUM_ROWS)\n",
    "\n",
    "    results = []\n",
    "    total_rows = len(df)\n",
    "    batch_start = 0\n",
    "\n",
    "    while batch_start < total_rows:\n",
    "        batch_end = min(batch_start + BATCH_SIZE, total_rows)\n",
    "        batch_df = df.iloc[batch_start:batch_end]\n",
    "\n",
    "        for idx, row in batch_df.iterrows():\n",
    "            nct_id = row.get(\"nct_id\", \"\")\n",
    "            intervention_text = row.get(\"description\", \"\")\n",
    "\n",
    "            if not isinstance(intervention_text, str) or not intervention_text.strip():\n",
    "                continue\n",
    "\n",
    "            user_prompt = USER_PROMPT_TEMPLATE.format(INTERVENTION_TEXT=intervention_text)\n",
    "            raw_output = call_azure_openai_api(SYSTEM_PROMPT, user_prompt)\n",
    "\n",
    "            results.append({\n",
    "                \"nct_id\": nct_id,\n",
    "                \"full_raw_response\": raw_output\n",
    "            })\n",
    "\n",
    "        out_df = pd.DataFrame(results)\n",
    "        out_df.to_excel(EXCEL_OUTPUT, index=False)\n",
    "        print(f\"Processed rows {batch_start} to {batch_end-1}, partial results -> {EXCEL_OUTPUT}\")\n",
    "\n",
    "        batch_start = batch_end\n",
    "\n",
    "    print(\"All done. Final file saved to:\", EXCEL_OUTPUT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON Prasing for Interventions\n",
    "\n",
    "DATA_FOLDER = \"/Users/davidshevchenko/Documents/Github/Clinical-Trials-Dashboard/data\"\n",
    "INPUT_FILE = os.path.join(DATA_FOLDER, \"ai_interventions.xlsx\")\n",
    "OUTPUT_FILE = os.path.join(DATA_FOLDER, \"ai_interventions_parsed.xlsx\")\n",
    "\n",
    "def main():\n",
    "    df = pd.read_excel(INPUT_FILE)\n",
    "\n",
    "    drug_names_col = []\n",
    "    dosages_col = []\n",
    "    administration_route_col = []\n",
    "    frequency_col = []\n",
    "    therapy_class_col = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        full_raw_response = row.get(\"full_raw_response\", \"\")\n",
    "        if not isinstance(full_raw_response, str) or not full_raw_response.strip():\n",
    "            drug_names_col.append([])\n",
    "            dosages_col.append([])\n",
    "            administration_route_col.append(\"N/A\")\n",
    "            frequency_col.append(\"N/A\")\n",
    "            therapy_class_col.append(\"N/A\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            parsed_json = json.loads(full_raw_response)\n",
    "\n",
    "            drug_names = parsed_json.get(\"drug_names\", [])\n",
    "            dosages = parsed_json.get(\"dosages\", [])\n",
    "            administration_route = parsed_json.get(\"administration_route\", \"N/A\")\n",
    "            frequency = parsed_json.get(\"frequency\", \"N/A\")\n",
    "            therapy_class = parsed_json.get(\"therapy_class\", \"N/A\")\n",
    "\n",
    "            drug_names_col.append(drug_names)\n",
    "            dosages_col.append(dosages)\n",
    "            administration_route_col.append(administration_route)\n",
    "            frequency_col.append(frequency)\n",
    "            therapy_class_col.append(therapy_class)\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            drug_names_col.append([])\n",
    "            dosages_col.append([])\n",
    "            administration_route_col.append(\"N/A\")\n",
    "            frequency_col.append(\"N/A\")\n",
    "            therapy_class_col.append(\"N/A\")\n",
    "\n",
    "    df[\"drug_names_parsed\"] = drug_names_col\n",
    "    df[\"dosages_parsed\"] = dosages_col\n",
    "    df[\"administration_route_parsed\"] = administration_route_col\n",
    "    df[\"frequency_parsed\"] = frequency_col\n",
    "    df[\"therapy_class_parsed\"] = therapy_class_col\n",
    "\n",
    "    df.to_excel(OUTPUT_FILE, index=False)\n",
    "    print(f\"Parsing complete. Output saved to: {OUTPUT_FILE}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON Prasing for Outcomes\n",
    "\n",
    "\n",
    "DATA_FOLDER = \"/Users/davidshevchenko/Documents/Github/Clinical-Trials-Dashboard/data\"\n",
    "INPUT_FILE = os.path.join(DATA_FOLDER, \"ai_outcomes.xlsx\")\n",
    "OUTPUT_FILE = os.path.join(DATA_FOLDER, \"ai_outcomes_parsed.xlsx\")\n",
    "\n",
    "def main():\n",
    "    df = pd.read_excel(INPUT_FILE)\n",
    "\n",
    "    key_variables_col = []\n",
    "    time_frame_col = []\n",
    "    outcome_category_col = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        full_raw_response = row.get(\"full_raw_response\", \"\")\n",
    "        if not isinstance(full_raw_response, str) or not full_raw_response.strip():\n",
    "            key_variables_col.append([])\n",
    "            time_frame_col.append(\"N/A\")\n",
    "            outcome_category_col.append(\"N/A\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            parsed_json = json.loads(full_raw_response)\n",
    "\n",
    "            key_variables = parsed_json.get(\"key_variables\", [])\n",
    "            time_frame = parsed_json.get(\"time_frame\", \"N/A\")\n",
    "            outcome_category = parsed_json.get(\"outcome_category\", \"N/A\")\n",
    "\n",
    "            key_variables_col.append(key_variables)\n",
    "            time_frame_col.append(time_frame)\n",
    "            outcome_category_col.append(outcome_category)\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            key_variables_col.append([])\n",
    "            time_frame_col.append(\"N/A\")\n",
    "            outcome_category_col.append(\"N/A\")\n",
    "\n",
    "    df[\"key_variables_parsed\"] = key_variables_col\n",
    "    df[\"time_frame_parsed\"] = time_frame_col\n",
    "    df[\"outcome_category_parsed\"] = outcome_category_col\n",
    "\n",
    "    df.to_excel(OUTPUT_FILE, index=False)\n",
    "    print(f\"Parsing complete. Output saved to: {OUTPUT_FILE}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DaveShevy-Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
